{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rospy, rosbag, tf\n",
    "import os, csv, time, argparse\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nav_msgs.msg import Odometry\n",
    "from geometry_msgs.msg import Twist\n",
    "from gazebo_msgs.msg import ModelStates\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from tf.transformations import euler_from_quaternion, quaternion_from_euler\n",
    "\n",
    "from src.VBOATS import VBOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_converter:\n",
    "    def __init__(self):\n",
    "        rospy.init_node('vboat_pipeline')\n",
    "        self.bridge = CvBridge()\n",
    "        self.image_pub = rospy.Publisher(\"/obstacles\",Image,queue_size=1000)\n",
    "        self.image_sub = rospy.Subscriber(\"/ugv/d415/depth/image_raw\",Image,self.callback)\n",
    "        \n",
    "        self.vboat = VBOATS()\n",
    "        self.vboat.dead_x = 0\n",
    "        self.vboat.dead_y = 6\n",
    "        self.r = rospy.Rate(40)\n",
    "        self.img = []\n",
    "        self.obs_disp = []\n",
    "        self.flag_initialization = True\n",
    "        self.nSamples = 100\n",
    "        self.dSum = 0\n",
    "        self.dmaxAvg = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def callback(self,data):\n",
    "        try:\n",
    "            cv_image = self.bridge.imgmsg_to_cv2(data, \"16UC1\")\n",
    "            cv_image = np.float32(cv_image)\n",
    "        except CvBridgeError as e: print(e)\n",
    "\n",
    "        if(self.flag_initialization):\n",
    "            self.dSum += np.max(cv_image)\n",
    "            self.count+=1\n",
    "            if(self.count == self.nSamples):\n",
    "                self.dmaxAvg = self.dSum / float(self.count)\n",
    "                print(\"Average Max Disparity: %.3f\" % (self.dmaxAvg))\n",
    "                self.flag_initialization = False\n",
    "                \n",
    "        if(not self.flag_initialization):\n",
    "            tmp = cv_image/65535\n",
    "            depth = np.uint8(tmp*255)\n",
    "#             depth = cv2.cvtColor(depth,cv2.COLOR_GRAY2BGR)\n",
    "            self.img = np.copy(depth)\n",
    "            self.vboat.pipeline(depth, threshU1=11,threshU2=20, threshV2=70)\n",
    "            display_obstacles = cv2.cvtColor(self.vboat.img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            for ob in self.vboat.obstacles:\n",
    "                cv2.rectangle(display_obstacles,ob[0],ob[1],(150,0,0),1)\n",
    "\n",
    "            try:\n",
    "                self.obs_disp = np.copy(display_obstacles)\n",
    "                self.image_pub.publish(self.bridge.cv2_to_imgmsg(display_obstacles, \"bgr8\"))\n",
    "            except CvBridgeError as e:\n",
    "                print(e)\n",
    "            \n",
    "    def start(self):\n",
    "        while not rospy.is_shutdown():\n",
    "            self.r.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Max Disparity: 65535.000\n"
     ]
    }
   ],
   "source": [
    "io = image_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(io.vboat.umap_raw)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(io.vboat.umap_processed)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(io.vboat.vmap_raw)\n",
    "plt.show()\n",
    "\n",
    "print(io.vboat.dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D415 Parameters returned from real camera\n",
    "rotation = [1, 0.000451149, 0.000541019, -0.000453043, 0.999994, 0.0035053, -0.000539434, -0.00350554, 0.999994]\n",
    "translation = [0.0150125, 2.66028e-05, -0.000210271]\n",
    "intrinsics = {\n",
    "    \"width\": 640, \"height\": 480, \n",
    "    \"ppx\": 320.551, \"ppy\": 232.202, \n",
    "    \"fx\": 626.464, \"fy\": 626.464, \n",
    "    \"model\": \"Brown Conrady\", \n",
    "    \"coeffs\": [0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "F = np.array([\n",
    "    [intrinsics['fx'], 0, intrinsics['ppx']],\n",
    "    [0, intrinsics['fy'], intrinsics['ppy']],\n",
    "    [0,0,1]\n",
    "])\n",
    "R = np.array(rotation).reshape((3, 3))\n",
    "Rinv = np.linalg.inv(R)\n",
    "T = np.array(translation).reshape((3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_camera_pose(cam_frame = '/ugv/d415_camera_depth_frame',base_frame = '/world'):\n",
    "    listener = tf.TransformListener()\n",
    "    listener.waitForTransform(base_frame,cam_frame, rospy.Time(0), rospy.Duration(8.0))\n",
    "    (trans,rot) = listener.lookupTransform(base_frame,cam_frame, rospy.Time(0))\n",
    "    roll,pitch,yaw = tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "    pose = np.array(trans+[np.rad2deg(yaw)])\n",
    "    return pose\n",
    "\n",
    "def get_distance(umap, xs, ds, ys, focal=[462.138,462.138], baseline=0.055, dscale=0.001, pp=[320.551,232.202], method=0):\n",
    "        nonzero = umap.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        good_inds = ((nonzeroy >= ds[0]) & (nonzeroy < ds[1]) &\n",
    "                     (nonzerox >= xs[0]) &  (nonzerox < xs[1])).nonzero()[0]\n",
    "\n",
    "        xmean = np.int(np.mean(nonzerox[good_inds]))\n",
    "        ymean = np.mean(ys)\n",
    "        dmean = np.mean(nonzeroy[good_inds])\n",
    "        \n",
    "        if(method == 1): \n",
    "            dist = (focal[0]*baseline)/dmean\n",
    "            z = dist*dscale\n",
    "        else:\n",
    "#             z = np.min(ds)*(65535/255)*dscale\n",
    "            z = dmean*(65535/255)*dscale\n",
    "        \n",
    "        # float x = (pixel[0] - intrin->ppx) / intrin->fx;\n",
    "        # float y = (pixel[1] - intrin->ppy) / intrin->fy;\n",
    "        x = (xmean - pp[0])/focal[0]\n",
    "        y = (ymean - pp[1])/focal[1]\n",
    "        \n",
    "#         x = (xmean)/focal[0]\n",
    "#         y = (ymean)/focal[1]\n",
    "        \n",
    "        x = x * z\n",
    "        y = y * z\n",
    "        print(\"Distance, X, Y: %.3f, %.3f, %.3f\" % (z, x,y))\n",
    "        return z, x,y, dmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstacle Disparities:\r\n",
      "[[15 17]\n",
      " [10 12]\n",
      " [ 9 11]]\n",
      "Obstacle X pixel ranges:  [456, 596] \r\n",
      "Obstacle Y pixel ranges:  [200, 320]\n",
      "Distance, X, Y: 2.379, 0.788, 0.106\n",
      "True Dist, Est. Dist (Method #1), Est. Dist (Method #2): 2.304, 2.313, 2.379\n",
      "\n",
      "[[ 0.74621415]\n",
      " [-0.21861631]] [ 0.19537242 -0.06194853]\n",
      "\n",
      "Obstacle Estimated Location:  [2.5231941247398515, -1.779643086472541]\n",
      "Obstacle True Location:  [ 2. -2.]\n"
     ]
    }
   ],
   "source": [
    "disp = np.zeros_like(io.vboat.img)\n",
    "disp = cv2.cvtColor(disp,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "umap = io.vboat.umap_raw\n",
    "xs = io.vboat.xBounds\n",
    "ds = np.array(io.vboat.dbounds)\n",
    "obs = io.vboat.obstacles\n",
    "\n",
    "ppx = 320.551; ppy = 232.202; fx = 626.464; fy = 626.464; b = 0.055\n",
    "pp = [ppx, ppy];   focal = [fx,fy]\n",
    "dGain = (65535/255)\n",
    "\n",
    "obid = 2\n",
    "X0 = np.array([\n",
    "    [4.0, -1.0, 0.227],\n",
    "    [3.0, 0, 0.177],\n",
    "    [2.0, -2.0, 0.344]\n",
    "])\n",
    "\n",
    "pose = get_camera_pose()\n",
    "Xk = pose[:2]; yaw = pose[-1]; ang = np.deg2rad(yaw)\n",
    "x1 = X0[obid,0];     y1 = X0[obid,1]\n",
    "dx = x1 - Xk[0];     dy = y1 - Xk[1]\n",
    "true_dist = np.sqrt(dx*dx + dy*dy)-X0[obid,2]\n",
    "\n",
    "print \"Obstacle Disparities:\\r\\n\", ds\n",
    "d = np.mean(ds[obid,0])\n",
    "z = d * dGain * 0.001\n",
    "tmpD = d* dGain\n",
    "dist = (fx*0.0150125)/(tmpD*0.001)\n",
    "# print(tmpD, z, dist)\n",
    "\n",
    "RotM = np.array([\n",
    "    [np.cos(ang), -np.sin(ang)],\n",
    "    [np.sin(ang), np.cos(ang)]\n",
    "])\n",
    "\n",
    "# Method 2: --------\n",
    "disparities = ds[obid]\n",
    "us = [obs[obid][0][0], obs[obid][1][0]]\n",
    "vs = [obs[obid][0][1], obs[obid][1][1]]\n",
    "print \"Obstacle X pixel ranges: \", us, \"\\r\\nObstacle Y pixel ranges: \", vs\n",
    "z2,ux,uy,_ = get_distance(umap,us,disparities,vs, focal=focal,pp=pp)\n",
    "\n",
    "print(\"True Dist, Est. Dist (Method #1), Est. Dist (Method #2): %.3f, %.3f, %.3f\" % (true_dist, z, z2) )\n",
    "\n",
    "pxl = np.array([ [ux],[uy],[z] ])\n",
    "pos = np.dot(Rinv, pxl)-T\n",
    "\n",
    "tmp = np.dot(mat,np.vstack([pos,1]))\n",
    "print\n",
    "# print tmp\n",
    "print np.dot(RotM,pos[:2]), Xk\n",
    "print\n",
    "\n",
    "xoff = np.tan(ang)*z\n",
    "zoff = uy/np.tan(ang)\n",
    "yoff = z / np.cos(ang)\n",
    "location = [yoff, np.asscalar(xoff-pos[0])]\n",
    "# print pos\n",
    "print \"Obstacle Estimated Location: \", location\n",
    "print \"Obstacle True Location: \", X0[obid,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = [0.444806, -0.559817]\n",
    "obs = [2.000000, -2]\n",
    "dx = bot[0] - obs[0]\n",
    "dy = bot[1] - obs[1]\n",
    "dist = np.sqrt(dx*dx + dy*dy)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = io.vboat.obstacles_umap[0]\n",
    "print(win)\n",
    "crop_img = io.vboat.umap_raw[win[0][1]:win[1][1], win[0][0]:win[1][0]]\n",
    "\n",
    "tmpMean = np.mean(crop_img)\n",
    "print(tmpMean)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(crop_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cam_frame = '/ugv/d415_camera_depth_optical_frame'\n",
    "cam_frame = '/ugv/d415_camera_depth_frame'\n",
    "base_frame = '/world'\n",
    "listener = tf.TransformListener()\n",
    "listener.waitForTransform(base_frame,cam_frame, rospy.Time(0), rospy.Duration(8.0))\n",
    "(trans,rot) = listener.lookupTransform(base_frame,cam_frame, rospy.Time(0))\n",
    "# listener.asMatrix(cam_frame)\n",
    "mat = tf.transformations.quaternion_matrix(rot)\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.dot(mat,np.vstack([pos,1]))\n",
    "print tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.dot(mat,np.vstack([pos,1]))\n",
    "print tmp\n",
    "print\n",
    "print pos\n",
    "print\n",
    "print xoff,yoff,zoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rospy, rosbag, tf\n",
    "import os, csv, time, argparse, math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nav_msgs.msg import Odometry\n",
    "from geometry_msgs.msg import Twist\n",
    "from gazebo_msgs.msg import ModelStates\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from tf.transformations import euler_from_quaternion, quaternion_from_euler\n",
    "\n",
    "from src.VBOATS import VBOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_converter:\n",
    "    def __init__(self):\n",
    "        rospy.init_node('vboat_pipeline')\n",
    "        self.bridge = CvBridge()\n",
    "        self.image_pub = rospy.Publisher(\"/obstacles\",Image,queue_size=1000)\n",
    "        self.image_sub = rospy.Subscriber(\"/ugv1/d415/depth/image_raw\",Image,self.callback)\n",
    "        \n",
    "        self.vboat = VBOATS()\n",
    "        self.vboat.dead_x = 0\n",
    "        self.vboat.dead_y = 6\n",
    "        self.r = rospy.Rate(40)\n",
    "        self.img = []\n",
    "        self.obs_disp = []\n",
    "        self.flag_initialization = False\n",
    "        self.nSamples = 100\n",
    "        self.dSum = 0\n",
    "        self.dmaxAvg = 0\n",
    "        self.count = 0\n",
    "        self.disp_obs = None\n",
    "        \n",
    "    def callback(self,data):\n",
    "        try:\n",
    "            cv_image = self.bridge.imgmsg_to_cv2(data, \"16UC1\")\n",
    "            cv_image = np.float32(cv_image)\n",
    "        except CvBridgeError as e: print(e)\n",
    "                \n",
    "        if(not self.flag_initialization):\n",
    "            tmp = cv_image/65535\n",
    "            depth = np.uint8(tmp*255)\n",
    "            self.img = np.copy(depth)\n",
    "            self.vboat.pipeline(depth, threshU1=11,threshU2=20, threshV2=70)\n",
    "            display_obstacles = cv2.cvtColor(self.vboat.img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            for ob in self.vboat.obstacles:\n",
    "                cv2.rectangle(display_obstacles,ob[0],ob[1],(150,0,0),1)\n",
    "\n",
    "            self.disp_obs = np.copy(display_obstacles)\n",
    "            try:\n",
    "                self.obs_disp = np.copy(display_obstacles)\n",
    "                self.image_pub.publish(self.bridge.cv2_to_imgmsg(display_obstacles, \"bgr8\"))\n",
    "            except CvBridgeError as e:\n",
    "                print(e)\n",
    "            \n",
    "    def start(self):\n",
    "        while not rospy.is_shutdown():\n",
    "            self.r.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = image_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(io.vboat.umap_raw)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(io.vboat.umap_processed)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(io.vboat.vmap_raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D415 Parameters returned from real camera\n",
    "rotation = [1, 0.000451149, 0.000541019, -0.000453043, 0.999994, 0.0035053, -0.000539434, -0.00350554, 0.999994]\n",
    "translation = [0.0150125, 2.66028e-05, -0.000210271]\n",
    "intrinsics = {\n",
    "    \"width\": 640, \"height\": 480, \n",
    "    \"ppx\": 320.551, \"ppy\": 232.202, \n",
    "    \"fx\": 626.464, \"fy\": 626.464, \n",
    "    \"model\": \"Brown Conrady\", \n",
    "    \"coeffs\": [0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "F = np.array([\n",
    "    [intrinsics['fx'], 0, intrinsics['ppx']],\n",
    "    [0, intrinsics['fy'], intrinsics['ppy']],\n",
    "    [0,0,1]\n",
    "])\n",
    "R = np.array(rotation).reshape((3, 3))\n",
    "Rinv = np.linalg.inv(R)\n",
    "T = np.array(translation).reshape((3, 1))\n",
    "T2 = np.array([intrinsics['ppx']*0.001, intrinsics['ppy']*0.001, 0, 0]).T\n",
    "print T.T\n",
    "print T2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_camera_pose(cam_frame = '/ugv1/d415_camera_depth_optical_frame',base_frame = '/ugv1/odom'):\n",
    "    listener = tf.TransformListener()\n",
    "    listener.waitForTransform(base_frame,cam_frame, rospy.Time(0), rospy.Duration(8.0))\n",
    "    (trans,rot) = listener.lookupTransform(base_frame,cam_frame, rospy.Time(0))\n",
    "    roll,pitch,yaw = tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "    pose = np.array(trans+[np.rad2deg(yaw)])\n",
    "    Tmat = np.array(trans).T\n",
    "    Rmat = tf.transformations.euler_matrix(roll,pitch,yaw,axes='sxyz')\n",
    "    return pose, Rmat, Tmat\n",
    "\n",
    "def get_distance(umap, xs, ds, ys, focal=[462.138,462.138], baseline=0.055, dscale=0.001, pp=[320.551,232.202], method=0, use_principle_point=False):\n",
    "        nonzero = umap.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        good_inds = ((nonzeroy >= ds[0]) & (nonzeroy < ds[1]) &\n",
    "                     (nonzerox >= xs[0]) &  (nonzerox < xs[1])).nonzero()[0]\n",
    "\n",
    "        xmean = np.int(np.mean(nonzerox[good_inds]))\n",
    "        ymean = np.mean(ys)\n",
    "        dmean = np.mean(nonzeroy[good_inds])\n",
    "        \n",
    "        if(method == 1): \n",
    "            dist = (focal[0]*baseline)/dmean\n",
    "            z = dist*dscale\n",
    "        else:\n",
    "#             z = np.min(ds)*(65535/255)*dscale\n",
    "            z = dmean*(65535/255)*dscale\n",
    "\n",
    "        if use_principle_point:\n",
    "            px = pp[0]\n",
    "            py = pp[1]\n",
    "        else:\n",
    "            px = 0\n",
    "            py = 0\n",
    "            \n",
    "        x = (xmean - px)/focal[0]\n",
    "        y = (ymean - py)/focal[1]\n",
    "        \n",
    "        x = x * z\n",
    "        y = y * z\n",
    "#         print(\"Distance, X, Y: %.3f, %.3f, %.3f\" % (z, x,y))\n",
    "        return z, x,y, dmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_terra = False\n",
    "umap = io.vboat.umap_raw\n",
    "xs = io.vboat.xBounds\n",
    "ds = np.array(io.vboat.dbounds)\n",
    "obs = io.vboat.obstacles\n",
    "\n",
    "ppx = 320.551; ppy = 232.202; fx = 626.464; fy = 626.464; b = 0.055\n",
    "pp = [ppx, ppy];   focal = [fx,fy]\n",
    "dGain = (65535/255)\n",
    "\n",
    "if(test_terra):\n",
    "    obid = 2\n",
    "    i = 1\n",
    "    # Obstacles terra world\n",
    "    X0 = np.array([\n",
    "        [4.0, -1.0, 0.227],\n",
    "        [3.0, 0, 0.177],\n",
    "        [2.0, -2.0, 0.344]\n",
    "    ])\n",
    "else:\n",
    "    obid = 0\n",
    "    i = 0\n",
    "    # Obstacles offset world\n",
    "#     X0 = np.array([\n",
    "#         [11.59, -3.6, 0.21336],\n",
    "#         [8.576193, -1.165787, 0.21336],\n",
    "#         [5.694473, 2.2, 0.21336]\n",
    "#     ])\n",
    "    X0 = np.array([ [5.0, -3.0, 0.21336] ])\n",
    "\n",
    "\n",
    "pose,RotM,Tmat = get_camera_pose()\n",
    "RotM = RotM[:3,:3]\n",
    "Xk = pose[:2]; yaw = pose[-1]; ang = np.deg2rad(yaw)\n",
    "x1 = X0[obid,0];     y1 = X0[obid,1]\n",
    "dx = x1 - Xk[0];     dy = y1 - Xk[1]\n",
    "true_dist = np.sqrt(dx*dx + dy*dy)-X0[obid,2]\n",
    "\n",
    "print \"Obstacle Disparities: \", ds\n",
    "\n",
    "d = np.mean(ds[i,0])#-1\n",
    "z2 = d * dGain * 0.001\n",
    "\n",
    "# Method 2: --------\n",
    "disparities = ds[i]\n",
    "disparities[0] = disparities[0] - 1\n",
    "us = [obs[i][0][0], obs[i][1][0]]\n",
    "vs = [obs[i][0][1], obs[i][1][1]]\n",
    "z,ux,uy,_ = get_distance(umap,us,disparities,vs, focal=focal,pp=pp,use_principle_point=True)\n",
    "\n",
    "\n",
    "theta = math.atan((ux/z))\n",
    "heading = math.atan(dy/dx)\n",
    "print(yaw,np.rad2deg(heading),np.rad2deg(theta))\n",
    "\n",
    "# print(\"True Dist, Est. Dist (Method #1), (Method #2): %.3f, %.3f, %.3f\" % (true_dist, z, z2) )\n",
    "\n",
    "pxl = np.array([ [ux],[uy],[z] ])\n",
    "RotMinv = np.linalg.inv(RotM.T)\n",
    "print(', '.join(map(str, np.around(Tmat.T,3))))\n",
    "Tmat = Tmat.reshape((3, 1))*-1\n",
    "pos = np.dot(RotMinv, pxl)\n",
    "tmp1 = pos - Tmat\n",
    "# tmp1[0] = tmp1[0] + Xk[0]\n",
    "\n",
    "print \"Camera Location: \", Xk#, yaw\n",
    "# print \"Obstacle Estimated Location: \", tmp1.T[0]\n",
    "# print \"Obstacle True Location: \", X0[obid,:2]\n",
    "\n",
    "strs = []\n",
    "strs.append(', '.join(map(str, np.around(pxl.T[0],3))))\n",
    "strs.append(', '.join(map(str, np.around(pos.T[0],3))))\n",
    "strs.append(', '.join(map(str, np.around(Tmat.T[0],3))))\n",
    "strs.append(', '.join(map(str, np.around(tmp1.T[0][:2],3))))\n",
    "strs.append(', '.join(map(str, np.around(X0[obid,:2],3))))\n",
    "# strs.append(', '.join(map(str, np.around(tmp1.T[0],3))))\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "Detected Obstacle Stats:\n",
    "========================\n",
    "\n",
    "    * Distances (True, Est.)    : %.3f, %.3f\n",
    "    * Pixel (X,Y,Z)             : %s\n",
    "    * Rotated Position (X,Y,Z)  : %s\n",
    "    * Translation (X,Y,Z)       : %s\n",
    "    \n",
    "    * Estimated Position (X,Y,Z): %s\n",
    "    * True Position (X,Y,Z)     : %s\n",
    "\"\"\" % (true_dist,z,strs[0],strs[1],strs[2],strs[3],strs[4]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = []\n",
    "strs.append(', '.join(map(str, np.around(pxl.T[0],3))))\n",
    "strs.append(', '.join(map(str, np.around(pos.T[0],3))))\n",
    "strs.append(', '.join(map(str, np.around(tmp1.T[0],3))))\n",
    "strs.append()\n",
    "# strs.append(', '.join(map(str, np.around(tmp1.T[0],3))))\n",
    "\n",
    "print(\"Test: %s\"%test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pxl = np.array([ [ux],[uy],[z] ])\n",
    "RotMinv = np.linalg.inv(RotM.T)\n",
    "# Tmat = Tmat.reshape((3, 1))*-1\n",
    "\n",
    "pos = np.dot(RotMinv, pxl)\n",
    "\n",
    "tmp1 = pos - Tmat\n",
    "tmp1[0] = tmp1[0] + Xk[0]\n",
    "\n",
    "print \"Pixel (X,Y,Z): \", pxl.T[0]\n",
    "print \"Position (X,Y,Z): \", pos.T[0]\n",
    "print Tmat.T\n",
    "print \"Temp (X,Y,Z): \", tmp1.T\n",
    "\n",
    "print \"Camera Location: \", Xk, yaw\n",
    "print \"Obstacle Estimated Location: \", tmp1.T\n",
    "print \"Obstacle True Location: \", X0[obid,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xoff = np.tan(ang)*z\n",
    "yoff = z / np.cos(ang)\n",
    "zoff = (fx*0.001)/np.tan(ang)\n",
    "\n",
    "offs = [xoff, yoff, zoff]\n",
    "location = [yoff, np.asscalar(xoff-pos[0])]\n",
    "# location = [yoff, np.asscalar(xoff+pos[0][0])]\n",
    "\n",
    "print \"Offsets: \", offs\n",
    "print \"Obstacle Estimated Location: \", location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpp = [0,1]\n",
    "t,p = tpp \n",
    "print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = [0.444806, -0.559817]\n",
    "obs = [2.000000, -2]\n",
    "dx = bot[0] - obs[0]\n",
    "dy = bot[1] - obs[1]\n",
    "dist = np.sqrt(dx*dx + dy*dy)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = io.vboat.obstacles_umap[0]\n",
    "print(win)\n",
    "crop_img = io.vboat.umap_raw[win[0][1]:win[1][1], win[0][0]:win[1][0]]\n",
    "\n",
    "tmpMean = np.mean(crop_img)\n",
    "print(tmpMean)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(crop_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cam_frame = '/ugv/d415_camera_depth_optical_frame'\n",
    "cam_frame = '/ugv/d415_camera_depth_optical_frame'\n",
    "base_frame = '/ugv/odom'\n",
    "listener = tf.TransformListener()\n",
    "listener.waitForTransform(base_frame,cam_frame, rospy.Time(0), rospy.Duration(8.0))\n",
    "(trans,rot) = listener.lookupTransform(base_frame,cam_frame, rospy.Time(0))\n",
    "roll,pitch,yaw = tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "print\n",
    "print np.rad2deg([roll,pitch,yaw])\n",
    "print\n",
    "print(tf.transformations.quaternion_matrix(rot))\n",
    "print\n",
    "rotot = tf.transformations.euler_matrix(roll,pitch,yaw).T\n",
    "print(rotot)\n",
    "print \n",
    "R11 = np.cos(pitch)*np.cos(yaw)\n",
    "R12 = np.cos(pitch)*np.sin(yaw)\n",
    "R13 = -np.sin(pitch)\n",
    "R1 = [R11, R12, R13]\n",
    "\n",
    "R21 = -(np.cos(roll)*np.sin(yaw)) + (np.sin(roll)*np.sin(pitch)*np.cos(yaw))\n",
    "R22 = (np.cos(roll)*np.cos(yaw)) + np.sin(roll)*np.sin(pitch)*np.sin(yaw)\n",
    "R23 = np.sin(roll)*np.cos(pitch)\n",
    "R2 = [R21,R22,R23]\n",
    "\n",
    "R31 = (np.sin(roll)*np.sin(yaw))+(np.cos(roll)*np.sin(pitch)*np.cos(yaw))\n",
    "R32 = -(np.sin(roll)*np.cos(yaw)) + (np.cos(roll)*np.sin(pitch)*np.sin(yaw))\n",
    "R33 = np.cos(roll)*np.cos(pitch)\n",
    "R3 = [R31,R32,R33]\n",
    "\n",
    "testRot = np.array([R1,R2,R3])\n",
    "print(testRot)\n",
    "print(testRot - rotot[:3,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxl = np.array([ [ux],[uy],[z] ])\n",
    "RotMinvT = np.linalg.inv(testRot)\n",
    "# Tmat = Tmat.reshape((3, 1))*-1\n",
    "\n",
    "poss = np.dot(RotMinvT, pxl)\n",
    "\n",
    "tmp1s = poss - Tmat\n",
    "# tmp1s[0] = tmp1s[0] + Xk[0]\n",
    "\n",
    "print \"Pixel (X,Y,Z): \", pxl.T[0]\n",
    "print \"Position (X,Y,Z): \", poss.T[0]\n",
    "print Tmat.T\n",
    "print \"Temp (X,Y,Z): \", tmp1s.T\n",
    "\n",
    "print \"Camera Location: \", Xk\n",
    "print \"Obstacle Estimated Location: \", tmp1s.T\n",
    "print \"Obstacle True Location: \", X0[obid,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.dot(mat,np.vstack([pos,1]))\n",
    "print tmp\n",
    "print\n",
    "print pos\n",
    "print\n",
    "print xoff,yoff,zoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t,r) = listener.lookupTransform(\"ugv/base_link\",cam_frame, rospy.Time(0))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.atan((0.5*640)/626.464)/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rospy, rosbag, tf\n",
    "import os, csv, time, argparse, math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nav_msgs.msg import Odometry\n",
    "from geometry_msgs.msg import Twist\n",
    "from gazebo_msgs.msg import ModelStates\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from tf.transformations import euler_from_quaternion, quaternion_from_euler\n",
    "\n",
    "from src.VBOATS import VBOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_converter:\n",
    "    def __init__(self):\n",
    "        rospy.init_node('vboat_pipeline')\n",
    "        self.bridge = CvBridge()\n",
    "        self.image_pub = rospy.Publisher(\"/obstacles\",Image,queue_size=1000)\n",
    "        self.image_sub = rospy.Subscriber(\"/ugv1/d415/depth/image_raw\",Image,self.callback)\n",
    "        \n",
    "        self.vboat = VBOATS()\n",
    "        self.vboat.dead_x = 0\n",
    "        self.vboat.dead_y = 6\n",
    "        self.r = rospy.Rate(40)\n",
    "        self.img = []\n",
    "        self.obs_disp = []\n",
    "        self.flag_initialization = False\n",
    "        self.nSamples = 100\n",
    "        self.dSum = 0\n",
    "        self.dmaxAvg = 0\n",
    "        self.count = 0\n",
    "        self.disp_obs = None\n",
    "        \n",
    "    def callback(self,data):\n",
    "        try:\n",
    "            cv_image = self.bridge.imgmsg_to_cv2(data, \"16UC1\")\n",
    "            cv_image = np.float32(cv_image)\n",
    "        except CvBridgeError as e: print(e)\n",
    "                \n",
    "        if(not self.flag_initialization):\n",
    "            tmp = cv_image/65535\n",
    "            depth = np.uint8(tmp*255)\n",
    "#             depth = cv2.cvtColor(depth,cv2.COLOR_GRAY2BGR)\n",
    "            self.img = np.copy(depth)\n",
    "            self.vboat.pipeline(depth, threshU1=11,threshU2=20, threshV2=70)\n",
    "            display_obstacles = cv2.cvtColor(self.vboat.img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            for ob in self.vboat.obstacles:\n",
    "                cv2.rectangle(display_obstacles,ob[0],ob[1],(150,0,0),1)\n",
    "\n",
    "            self.disp_obs = np.copy(display_obstacles)\n",
    "            try:\n",
    "                self.obs_disp = np.copy(display_obstacles)\n",
    "                self.image_pub.publish(self.bridge.cv2_to_imgmsg(display_obstacles, \"bgr8\"))\n",
    "            except CvBridgeError as e:\n",
    "                print(e)\n",
    "            \n",
    "    def start(self):\n",
    "        while not rospy.is_shutdown():\n",
    "            self.r.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = image_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(io.vboat.umap_raw)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(io.vboat.umap_processed)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(io.vboat.vmap_raw)\n",
    "plt.show()\n",
    "\n",
    "print(io.vboat.dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.50125e-02  2.66028e-05 -2.10271e-04]]\n",
      "[0.320551 0.232202 0.       0.      ]\n"
     ]
    }
   ],
   "source": [
    "# D415 Parameters returned from real camera\n",
    "rotation = [1, 0.000451149, 0.000541019, -0.000453043, 0.999994, 0.0035053, -0.000539434, -0.00350554, 0.999994]\n",
    "translation = [0.0150125, 2.66028e-05, -0.000210271]\n",
    "intrinsics = {\n",
    "    \"width\": 640, \"height\": 480, \n",
    "    \"ppx\": 320.551, \"ppy\": 232.202, \n",
    "    \"fx\": 626.464, \"fy\": 626.464, \n",
    "    \"model\": \"Brown Conrady\", \n",
    "    \"coeffs\": [0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "F = np.array([\n",
    "    [intrinsics['fx'], 0, intrinsics['ppx']],\n",
    "    [0, intrinsics['fy'], intrinsics['ppy']],\n",
    "    [0,0,1]\n",
    "])\n",
    "R = np.array(rotation).reshape((3, 3))\n",
    "Rinv = np.linalg.inv(R)\n",
    "T = np.array(translation).reshape((3, 1))\n",
    "T2 = np.array([intrinsics['ppx']*0.001, intrinsics['ppy']*0.001, 0, 0]).T\n",
    "print T.T\n",
    "print T2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_camera_pose(cam_frame = '/ugv1/d415_camera_depth_optical_frame',base_frame = '/ugv1/odom'):\n",
    "    listener = tf.TransformListener()\n",
    "    listener.waitForTransform(base_frame,cam_frame, rospy.Time(0), rospy.Duration(8.0))\n",
    "    (trans,rot) = listener.lookupTransform(base_frame,cam_frame, rospy.Time(0))\n",
    "    roll,pitch,yaw = tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "    pose = np.array(trans+[np.rad2deg(yaw)])\n",
    "    Tmat = np.array(trans).T\n",
    "    Rmat = tf.transformations.quaternion_matrix(rot)\n",
    "    return pose, Rmat, Tmat\n",
    "\n",
    "def get_distance(umap, xs, ds, ys, focal=[462.138,462.138], baseline=0.055, dscale=0.001, pp=[320.551,232.202], method=0):\n",
    "        nonzero = umap.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        good_inds = ((nonzeroy >= ds[0]) & (nonzeroy < ds[1]) &\n",
    "                     (nonzerox >= xs[0]) &  (nonzerox < xs[1])).nonzero()[0]\n",
    "\n",
    "        xmean = np.int(np.mean(nonzerox[good_inds]))\n",
    "        ymean = np.mean(ys)\n",
    "        dmean = np.mean(nonzeroy[good_inds])\n",
    "        \n",
    "        if(method == 1): \n",
    "            dist = (focal[0]*baseline)/dmean\n",
    "            z = dist*dscale\n",
    "        else:\n",
    "#             z = np.min(ds)*(65535/255)*dscale\n",
    "            z = dmean*(65535/255)*dscale\n",
    "        \n",
    "        # float x = (pixel[0] - intrin->ppx) / intrin->fx;\n",
    "        # float y = (pixel[1] - intrin->ppy) / intrin->fy;\n",
    "#         x = (xmean - pp[0])/focal[0]\n",
    "#         y = (ymean - pp[1])/focal[1]\n",
    "        \n",
    "        x = (xmean)/focal[0]\n",
    "        y = (ymean)/focal[1]\n",
    "        \n",
    "        x = x * z\n",
    "        y = y * z\n",
    "        print(\"Distance, X, Y: %.3f, %.3f, %.3f\" % (z, x,y))\n",
    "        return z, x,y, dmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstacle Disparities:\r\n",
      "[[ 9 11]]\n",
      "\n",
      "Distance, X, Y: 2.420, 1.298, 1.004\n",
      "True Dist, Est. Dist (Method #1), (Method #2): 3.498, 2.313, 2.420\n",
      "\n",
      "Pixel (X,Y,Z):  [1.29777964 1.00423425 2.313     ]\n",
      "Position (X,Y,Z):  [ 1.61635077 -2.31262357 -0.18209875  1.        ]\n",
      "Temp (X,Y,Z):  [-9.28220379 -6.04064198 -9.6091817  -7.60486947]\n",
      "\n",
      "\n",
      "\n",
      "Offsets:  [2.2413414529787055, 3.220804326381951, 0.6464928536766624]\n",
      "\n",
      "Camera Location:  [ 8.60486947 -0.10303901] 44.098575810654054\n",
      "Obstacle Estimated Location:  [3.220804326381951, 3.857692222454809]\n",
      "Obstacle True Location:  [5.694473 2.2     ]\n"
     ]
    }
   ],
   "source": [
    "test_terra = False\n",
    "disp = np.zeros_like(io.vboat.img)\n",
    "disp = cv2.cvtColor(disp,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "umap = io.vboat.umap_raw\n",
    "xs = io.vboat.xBounds\n",
    "ds = np.array(io.vboat.dbounds)\n",
    "obs = io.vboat.obstacles\n",
    "\n",
    "ppx = 320.551; ppy = 232.202; fx = 626.464; fy = 626.464; b = 0.055\n",
    "pp = [ppx, ppy];   focal = [fx,fy]\n",
    "dGain = (65535/255)\n",
    "\n",
    "if(test_terra):\n",
    "    obid = i = 0\n",
    "    # Obstacles terra world\n",
    "    X0 = np.array([\n",
    "        [4.0, -1.0, 0.227],\n",
    "        [3.0, 0, 0.177],\n",
    "        [2.0, -2.0, 0.344]\n",
    "    ])\n",
    "else:\n",
    "    obid = 2\n",
    "    i = 0\n",
    "    # Obstacles offset world\n",
    "    X0 = np.array([\n",
    "        [11.59, -3.6, 0.21336],\n",
    "        [8.576193, -1.165787, 0.21336],\n",
    "        [5.694473, 2.2, 0.21336]\n",
    "    ])\n",
    "\n",
    "\n",
    "pose,RotM,Tmat = get_camera_pose()\n",
    "Xk = pose[:2]; yaw = pose[-1]; ang = np.deg2rad(yaw)\n",
    "x1 = X0[obid,0];     y1 = X0[obid,1]\n",
    "dx = x1 - Xk[0];     dy = y1 - Xk[1]\n",
    "true_dist = np.sqrt(dx*dx + dy*dy)-X0[obid,2]\n",
    "\n",
    "print \"Obstacle Disparities:\\r\\n\", ds\n",
    "print\n",
    "d = np.mean(ds[i,0])\n",
    "z = d * dGain * 0.001\n",
    "tmpD = d* dGain\n",
    "dist = (fx*0.0150125)/(tmpD*0.001)\n",
    "# print(tmpD, z, dist)\n",
    "\n",
    "# Method 2: --------\n",
    "disparities = ds[i]\n",
    "us = [obs[i][0][0], obs[i][1][0]]\n",
    "vs = [obs[i][0][1], obs[i][1][1]]\n",
    "z2,ux,uy,_ = get_distance(umap,us,disparities,vs, focal=focal,pp=pp)\n",
    "\n",
    "# print \"Obstacle X pixel ranges: \", us, \"\\r\\nObstacle Y pixel ranges: \", vs\n",
    "print(\"True Dist, Est. Dist (Method #1), (Method #2): %.3f, %.3f, %.3f\" % (true_dist, z, z2) )\n",
    "\n",
    "pxl = np.array([ [ux],[uy],[z] ])\n",
    "tpxl = np.vstack([pxl,1])\n",
    "\n",
    "RotMinv = np.linalg.inv(RotM)\n",
    "pos = np.dot(RotMinv, tpxl)-np.vstack([T,0])\n",
    "tpos = np.vstack([pos,1])\n",
    "\n",
    "tmp1 = np.dot(RotM,tpxl)-Tmat\n",
    "# tmp2 = np.dot(mat,tpos)\n",
    "\n",
    "print\n",
    "print \"Pixel (X,Y,Z): \", pxl.T[0]\n",
    "print \"Position (X,Y,Z): \", pos.T[0]\n",
    "print \"Temp (X,Y,Z): \", tmp1.T[0]\n",
    "print\n",
    "# print np.dot(RotM,pos[:2]).T\n",
    "print\n",
    "\n",
    "xoff = np.tan(ang)*z\n",
    "yoff = z / np.cos(ang)\n",
    "zoff = (fx*0.001)/np.tan(ang)\n",
    "\n",
    "offs = [xoff, yoff, zoff]\n",
    "\n",
    "print\n",
    "print \"Offsets: \", offs\n",
    "print\n",
    "\n",
    "# location = [yoff, np.asscalar(xoff-pos[0])]\n",
    "location = [yoff, np.asscalar(xoff+pos[0])]\n",
    "# print pos\n",
    "print \"Camera Location: \", Xk, yaw\n",
    "print \"Obstacle Estimated Location: \", location\n",
    "print \"Obstacle True Location: \", X0[obid,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "34212.933/3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = [0.444806, -0.559817]\n",
    "obs = [2.000000, -2]\n",
    "dx = bot[0] - obs[0]\n",
    "dy = bot[1] - obs[1]\n",
    "dist = np.sqrt(dx*dx + dy*dy)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = io.vboat.obstacles_umap[0]\n",
    "print(win)\n",
    "crop_img = io.vboat.umap_raw[win[0][1]:win[1][1], win[0][0]:win[1][0]]\n",
    "\n",
    "tmpMean = np.mean(crop_img)\n",
    "print(tmpMean)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(crop_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam_frame = '/ugv/d415_camera_depth_optical_frame'\n",
    "cam_frame = '/ugv1/d415_camera_depth_optical_frame'\n",
    "base_frame = '/ugv1/odom'\n",
    "listener = tf.TransformListener()\n",
    "listener.waitForTransform(base_frame,cam_frame, rospy.Time(0), rospy.Duration(8.0))\n",
    "(trans,rot) = listener.lookupTransform(base_frame,cam_frame, rospy.Time(0))\n",
    "# listener.asMatrix(cam_frame)\n",
    "mat = tf.transformations.quaternion_matrix(rot)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.dot(mat,np.vstack([pos,1]))\n",
    "print tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.dot(mat,np.vstack([pos,1]))\n",
    "print tmp\n",
    "print\n",
    "print pos\n",
    "print\n",
    "print xoff,yoff,zoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.atan((0.5*640)/626.464)/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

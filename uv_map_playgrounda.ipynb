{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "import os, sys, fnmatch\n",
    "import cv2, time\n",
    "import numpy as np\n",
    "import argparse, pprint\n",
    "import matplotlib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.transforms import Bbox\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, IntSlider, Layout, interact_manual,interact, HBox, Layout,VBox\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "homeDir = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def grab_dir_images(_dir, patterns = ['*png','*jpg'],verbose=False):\n",
    "    found = []\n",
    "    for root, dirs, files in os.walk(_dir):\n",
    "        for pat in patterns:\n",
    "            for file in files:\n",
    "                if fnmatch.fnmatch(file, pat):\n",
    "                    found.append(os.path.join(root, file))\n",
    "    \n",
    "    if(verbose): print(found)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img,figNum=None):\n",
    "    if(figNum == None): plt.figure()\n",
    "    else: plt.figure(figNum)\n",
    "        \n",
    "    plt.imshow(img)\n",
    "    plt.subplots_adjust(wspace=0.0,hspace=0.0,left=0.0,right=1.0,top=1.0, bottom=0.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uvMapping(_img, get_overlay=True,verbose=False):\n",
    "    overlay = None\n",
    "    h,w = _img.shape\n",
    "    histRange = (0,256)\n",
    "    histSz = np.max(_img) + 1\n",
    "    if(verbose): print(\"[UV Mapping] Input Image Size: (%d, %d)\" % (h,w))\n",
    "\n",
    "    umap = np.zeros((histSz,w,1), dtype=np.uint8)\n",
    "    vmap = np.zeros((h,histSz,1), dtype=np.uint8)\n",
    "\n",
    "    for i in range(0,h):\n",
    "        vscan = _img[i,:]\n",
    "        vrow = cv2.calcHist([vscan],[0],None,[histSz],histRange)\n",
    "        if(verbose): print(\"\\t[V Mapping] Scan [%d] (%s) ---- Scan Histogram (%s)\" % (i,', '.join(map(str, vscan.shape)), ', '.join(map(str, vrow.shape))))\n",
    "        vmap[i,:] = vrow\n",
    "\n",
    "    for i in range(0,w):\n",
    "        uscan = _img[:,i]\n",
    "        urow = cv2.calcHist([uscan],[0],None,[histSz],histRange)\n",
    "        if(verbose): print(\"\\t[U Mapping] Scan[%d] (%s) ---- Scan Histogram (%s)\" % (i,', '.join(map(str, uscan.shape)), ', '.join(map(str, urow.shape))))\n",
    "        umap[:,i] = urow\n",
    "\n",
    "    umap = np.reshape(umap,(histSz,w))\n",
    "    vmap = np.reshape(vmap,(h,histSz))\n",
    "\n",
    "    if(get_overlay):\n",
    "        blank = np.ones((umap.shape[0],vmap.shape[1]),np.uint8)*255\n",
    "        pt1 = np.concatenate((_img, vmap), axis=1)\n",
    "        pt2 = np.concatenate((umap,blank),axis=1)\n",
    "        overlay = np.concatenate((pt1,pt2),axis=0)\n",
    "        overlay = cv2.cvtColor(overlay,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if(verbose):\n",
    "        print(\"\\t[UV Mapping] U Map = (%s) ----- V Map = (%s)\" % (', '.join(map(str, umap.shape)),', '.join(map(str, vmap.shape)) ))\n",
    "    return umap,vmap,overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_helper_img(_imgs,cspace=cv2.COLOR_GRAY2BGR):\n",
    "    print(_imgs[0].shape)\n",
    "    n,m = _imgs[0].shape[0], _imgs[0].shape[1]\n",
    "    print(n,m)\n",
    "    \n",
    "    bborder = np.ones((5,m,3),dtype=np.uint8)\n",
    "    sborder = np.ones((n,5,3),dtype=np.uint8)\n",
    "    cborder = np.ones((5,5,3),dtype=np.uint8)\n",
    "    bborder[np.where((bborder==[1,1,1]).all(axis=2))] = [255,0,255]\n",
    "    sborder[np.where((sborder==[1,1,1]).all(axis=2))] = [255,0,255]\n",
    "    cborder[np.where((cborder==[1,1,1]).all(axis=2))] = [255,0,255]\n",
    "    \n",
    "    imgs = []\n",
    "    for img in _imgs:\n",
    "        im = None\n",
    "        try:\n",
    "            im = cv2.cvtColor(img,cspace)\n",
    "        except:\n",
    "            im = img\n",
    "        imgs.append(im)\n",
    "    \n",
    "    helper_img_t = np.concatenate(\n",
    "        (\n",
    "            np.concatenate((imgs[0],sborder), axis=1),\n",
    "            np.concatenate((imgs[1],sborder), axis=1),\n",
    "            np.concatenate((imgs[2],sborder), axis=1)\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    helper_img_m = np.concatenate(\n",
    "        (\n",
    "            np.concatenate((bborder,cborder), axis=1),\n",
    "            np.concatenate((bborder,cborder), axis=1),\n",
    "            np.concatenate((bborder,cborder), axis=1)\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    helper_img_b = np.concatenate(\n",
    "        (\n",
    "            np.concatenate((imgs[3],sborder), axis=1),\n",
    "            np.concatenate((imgs[4],sborder), axis=1),\n",
    "            np.concatenate((imgs[5],sborder), axis=1)\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    helper_img = np.concatenate((helper_img_t,helper_img_m,helper_img_b), axis=0)\n",
    "    return helper_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_horizontals(_img,threshold, show_contours=True,verbose=False):\n",
    "    try: img = cv2.cvtColor(_img,cv2.COLOR_BGR2GRAY)\n",
    "    except: img = _img\n",
    "    n,m = img.shape[0], img.shape[1]\n",
    "    print(\"Countours:\", img.shape)\n",
    "    _, contours, hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "    \n",
    "    filtered_cnts = [cnt for cnt in contours if cv2.contourArea(cnt) >= threshold]\n",
    "    filtered_areas = [cv2.contourArea(cnt) for cnt in filtered_cnts]\n",
    "    \n",
    "    # Find horizontal limits\n",
    "    limits = []; ellipses = []; pts = []; centers = []\n",
    "    count = 0\n",
    "    for cnt in filtered_cnts:\n",
    "        ellipse = cv2.fitEllipse(cnt)\n",
    "        cx, cy = np.int32(ellipse[0])\n",
    "        h, w = np.int32(ellipse[1])\n",
    "        dx,dy = w/2,h/2\n",
    "        \n",
    "        if(verbose):\n",
    "            print(\"Center: (%d, %d)\" % (cx,cy))\n",
    "            print(\"H, W: (%d, %d)\" % (dx,dy))\n",
    "\n",
    "        xr = cx + dx; xl = cx - dx\n",
    "        yt = cy - dy; yb = cy + dy        \n",
    "        ptL = (xl,cy); ptR = (xr,cy)\n",
    "        \n",
    "        lim = np.array([[xl,xr],[yt,yb]])\n",
    "        limits.append(lim)\n",
    "        \n",
    "        pts.append([ptL, ptR])\n",
    "        ellipses.append(ellipse)\n",
    "        centers.append((cx,cy))        \n",
    "        count+=1\n",
    "        \n",
    "    if(verbose):\n",
    "        print(\"Raw Contour Areas:\",areas)\n",
    "        print(\"Filtered Contour Areas:\",filtered_areas)\n",
    "    \n",
    "    \n",
    "    if(show_contours):\n",
    "        helper1 = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "        helper2 = np.copy(helper1)\n",
    "        helper_in = np.copy(helper1)\n",
    "        for i in range(count):\n",
    "            cnt = filtered_cnts[i]\n",
    "            cv2.drawContours(helper1, [cnt], 0, (255,255,255), 2)\n",
    "            cv2.ellipse(helper2,ellipses[i],(0,255,0),2)\n",
    "            cv2.circle(helper2,centers[i],2,(255,0,255), 5)\n",
    "            cv2.circle(helper2,pts[i][0],2,(0,255,255), 5)\n",
    "            cv2.circle(helper2,pts[i][1],2,(0,255,255), 5)\n",
    "    \n",
    "        sborder = np.ones((n,5,3),dtype=np.uint8)\n",
    "        sborder[np.where((sborder==[1,1,1]).all(axis=2))] = [255,0,255]\n",
    "        helper = np.concatenate((\n",
    "            np.concatenate((helper_in,sborder), axis=1),\n",
    "            np.concatenate((helper1,sborder), axis=1),\n",
    "            np.concatenate((helper2,sborder), axis=1)\n",
    "        ), axis=1)\n",
    "        plot_image(helper,3)\n",
    "        \n",
    "    return filtered_cnts, limits, ellipses, pts, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_new_img = False\n",
    "last_img = None\n",
    "input_img = None\n",
    "umap = None\n",
    "vmap = None\n",
    "overlay = None\n",
    "helper_img = None\n",
    "filtered = None\n",
    "cpy1 = None\n",
    "cpy2 = None\n",
    "pre_filter = None\n",
    "\n",
    "prev_e1,prev_e2,prev_greyThresh = 0, 0, 0\n",
    "prev_map = False\n",
    "\n",
    "found_imgs = grab_dir_images(homeDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_finder(\n",
    "    _img=\"test/test_disparity.png\", method = 1, line_input_method = 0, e1 = 2, e2 = 5,\n",
    "    ang = 90, rho = 1, minLineLength = 11, maxLineGap = 11, houghThresh = 50, greyThresh = 11,\n",
    "    cnt_thresh = 500.0, show_helpers = True, use_umap = True, flip_thresh_bin = False\n",
    "    ):\n",
    "    \n",
    "    global filtered, pre_filter, umap, vmap, cpy1, cpy2, overlay, helper_img, prev_img\n",
    "    global flag_new_img, last_img, prev_e1, prev_e2, prev_greyThresh, prev_map\n",
    "    \n",
    "    \"\"\"\n",
    "    Parse Input Variables to Create string desscriptors for easier control variable copying\n",
    "    \"\"\"\n",
    "    if(line_input_method is 1): filter_meth = \"Composite Filtering -> Blurring\"\n",
    "    elif(line_input_method is 2): filter_meth = \"Composite Filtering -> Canny Edges\"\n",
    "    else: filter_meth = \"Basic Thresholding\"\n",
    "        \n",
    "    if(method is 0): line_meth = \"Standard Hough Transform\"\n",
    "    else: line_meth = \"Probablistic Hough Transform\"\n",
    "    \n",
    "    if(use_umap): map_space = \"U-Map\"\n",
    "    else: map_space = \"V-Map\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Check control variable arguments for changes to reduce repeating unnecessary calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if we are testing for a different image\n",
    "    if(last_img == _img): flag_new_img = False\n",
    "    else: flag_new_img = True\n",
    "\n",
    "    # Check if we need to perform image filtering again\n",
    "    if((prev_map is not use_umap) or (flag_new_img) or\n",
    "       (prev_greyThresh is not greyThresh) or \n",
    "       (prev_e1 is not e1) or \n",
    "       (prev_e2 is not e2)\n",
    "    ):\n",
    "        flag_needs_filtering = True\n",
    "        print(\"Images need to be filtered again...\")\n",
    "    else:\n",
    "        flag_needs_filtering = True\n",
    "        print(\"Skipping image filtering...\")\n",
    "    \n",
    "    last_img, prev_e1, prev_e2, prev_greyThresh, prev_map = _img, e1, e2, greyThresh, use_umap\n",
    "    \n",
    "    print(\n",
    "    \"\"\"\n",
    "    Inputs:  (image = %s)\n",
    "    ------\n",
    "    \n",
    "    \\t* Mapping Space       : %s\n",
    "    \\t* Line Finding Method : %s\n",
    "    \\t* Filtering Used      : %s\n",
    "    \\t* Kernel Size         : (%d, %d)\n",
    "    \\t* Rho, Angle (deg)    :  %d, %d\n",
    "    \\t* Min Line Length     :  %d\n",
    "    \\t* Max Line Gap        :  %d\n",
    "    \\t* Grey Thresholding   :  %d\n",
    "    \\t* Hough Threshold     :  %d\n",
    "    \\t* Contour Threshold   :  %d\n",
    "    \"\"\" % (\n",
    "        _img,map_space,line_meth,filter_meth,e1,e2,rho,ang,minLineLength,maxLineGap,greyThresh,houghThresh,cnt_thresh\n",
    "    ))\n",
    "    \n",
    "    # Convert Angle to radians for calculations\n",
    "    ang = ang * np.pi/180\n",
    "    img = cv2.imread(_img,cv2.IMREAD_GRAYSCALE)\n",
    "    if(flag_new_img): \n",
    "        print(\"Mapping new image into UV Map\")\n",
    "        umap,vmap, overlay = uvMapping(img)\n",
    "\n",
    "    if(use_umap): tmpIn = np.copy(umap)\n",
    "    else: tmpIn = np.copy(vmap)\n",
    "\n",
    "    tmp = cv2.cvtColor(tmpIn,cv2.COLOR_GRAY2BGR)\n",
    "    n,m,_ = tmp.shape\n",
    "    filtered = np.zeros((n,m,3),dtype=np.uint8)\n",
    "\n",
    "    if(flag_needs_filtering):\n",
    "        if(flip_thresh_bin): masking = cv2.THRESH_BINARY_INV\n",
    "        else: masking = cv2.THRESH_BINARY\n",
    "            \n",
    "        kernel = np.ones((e1,e2),np.uint8)\n",
    "        kernel2 = np.ones((4,4),np.uint8)\n",
    "\n",
    "        ret, grey = cv2.threshold(tmpIn,greyThresh,255,masking)\n",
    "        dilation = cv2.dilate(grey,kernel,iterations = 1)\n",
    "        blur = cv2.GaussianBlur(dilation,(5,5),0)\n",
    "        closing = cv2.morphologyEx(grey,cv2.MORPH_CLOSE,kernel, iterations = 2)\n",
    "\n",
    "        ret, grey_thresh = cv2.threshold(grey,greyThresh,255,masking)\n",
    "        ret, close_thresh = cv2.threshold(closing,greyThresh,255,masking)\n",
    "        canny = cv2.Canny(blur,25,200,apertureSize = 3)\n",
    "\n",
    "        helper_imgs = [tmp,grey,dilation,blur,closing,canny]\n",
    "        helper_img = construct_helper_img(helper_imgs)\n",
    "        \n",
    "    if(line_input_method is 1): hlines = blur\n",
    "    elif(line_input_method is 2): hlines = canny\n",
    "    else: hlines = grey\n",
    "#     cv2.imwrite('input-lines.png',hlines)\n",
    "    try:\n",
    "        if(method==0):\n",
    "            lines = cv2.HoughLines(hlines,rho,ang,houghThresh)\n",
    "            count = 0\n",
    "            for rho,theta in lines[0]:\n",
    "                count+=1\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "\n",
    "                cv2.line(tmp,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "                cv2.line(filtered,(x1,y1),(x2,y2),(255,255,255),2)\n",
    "        else:\n",
    "            lines = cv2.HoughLinesP(hlines,rho,ang,houghThresh,minLineLength,maxLineGap)\n",
    "            for x in range(0, len(lines)):\n",
    "                for x1,y1,x2,y2 in lines[x]:\n",
    "                    cv2.line(tmp,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    cv2.line(filtered,(x1,y1),(x2,y2),(255,255,255),2)\n",
    "    except:\n",
    "        print(\"Couldn't Find Hough Lines!!!\")\n",
    "        pass\n",
    "    \n",
    "    if(flag_new_img): plot_image(overlay,0)    \n",
    "    if(flag_needs_filtering and show_helpers): plot_image(helper_img,1)\n",
    "    try: plot_image(filtered,2)\n",
    "    except: pass\n",
    "\n",
    "    # CONTOUR SECTIION    \n",
    "    pre_filter = cv2.GaussianBlur(filtered,(5,5),0)\n",
    "#     try: cv2.imwrite('pre-filtered-lines.png',pre_filter)\n",
    "#     except: pass\n",
    "    pre_filter = cv2.cvtColor(pre_filter,cv2.COLOR_BGR2GRAY)\n",
    "    abstract_horizontals(pre_filter,cnt_thresh)\n",
    "\n",
    "    tmpI = np.copy(img)\n",
    "    indices = np.argwhere(pre_filter == 255)\n",
    "#     print(indices.shape)\n",
    "    indices = indices[:,:2]\n",
    "    disparity_filters = indices[:,0]\n",
    "#     pp.pprint(disparity_filters)\n",
    "    \n",
    "    tmpI[np.isin(tmpI, disparity_filters)] = 0\n",
    "    plot_image(pre_filter,8)\n",
    "    plot_image(cv2.cvtColor(tmpI,cv2.COLOR_GRAY2BGR),9)\n",
    "    \n",
    "    print(\" ============  Plotting Done !! =================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "flag_new_img = False\n",
    "last_img = None\n",
    "# umap = None\n",
    "# vmap = None\n",
    "# overlay = None\n",
    "# helper_img = None\n",
    "# filtered = None\n",
    "# cpy1 = None\n",
    "# cpy2 = None\n",
    "# pre_filter = None\n",
    "\n",
    "prev_e1,prev_e2,prev_greyThresh = 0, 0, 0\n",
    "prev_map = False\n",
    "\n",
    "found_imgs = grab_dir_images(homeDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb776688f1246d995d88ef081a5a120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oVkJveChjaGlsZHJlbj0oSEJveChjaGlsZHJlbj0oU2VsZWN0KGRlc2NyaXB0aW9uPXUnRmlsZTonLCBsYXlvdXQ9TGF5b3V0KHdpZHRoPXUnMTAwJScpLCBvcHRpb27igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "#\n",
    "# =========================================================\n",
    "p = interactive(line_finder,\n",
    "    _img = widgets.Select(\n",
    "                        options=sorted(found_imgs),\n",
    "                        value=str(sorted(found_imgs)[0]),\n",
    "                        description='File:',\n",
    "                        layout=Layout(width='100%')\n",
    "                    ),\n",
    "    method = {'Standard Hough Transform':0,'Probabilistic Hough Transform':1},\n",
    "    line_input_method = {'Classic Thresholded':0,'Morphed Thresholded':1,'Canny Edges':2},\n",
    "    e1 = (1,255,1), e2 = (1,255,1),\n",
    "    ang = (0,360,1), rho = (1,1000,1),\n",
    "    minLineLength = (0,255,1), maxLineGap = (0,255,1),\n",
    "    houghThresh = (0,255,1), greyThresh = (0,255,1), cnt_thresh = (0,5000,100),\n",
    "    show_helpers = True, use_umap = True, flip_thresh_bin = False\n",
    ")\n",
    "\n",
    "\n",
    "row1 = HBox([p.children[0]])\n",
    "row2 = HBox([p.children[1], p.children[2]], layout = Layout(flex_flow='row wrap'))\n",
    "row3 = HBox([p.children[3], p.children[4]], layout = Layout(flex_flow='row wrap'))\n",
    "row4 = HBox([p.children[5], p.children[6], p.children[7], p.children[8]], layout = Layout(display='flex',flex_flow='row'))\n",
    "row5 = HBox([p.children[9], p.children[10], p.children[11]], layout = Layout(flex_flow='row wrap'))\n",
    "row6 = HBox([p.children[12], p.children[13], p.children[14]], layout = Layout(flex_flow='row wrap'))\n",
    "controls = VBox([row1,row2,row3,row4,row5,row6], layout = Layout(display='flex'))\n",
    "output = p.children[-1]\n",
    "display(VBox([controls, output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good Configuration:    for image = test/test_disparity.png)\n",
      "---------------------------------------------------------------\n",
      "    \n",
      "    * Mapping Space       : U-Map\n",
      "    * Line Finding Method : Probablistic Hough Transform\n",
      "    * Filtering Used      : Composite Filtering -> Blurring\n",
      "    * Kernel Size         : (2, 3)\n",
      "    * Rho, Angle (deg)    :  1, 90\n",
      "    * Min Line Length     :  11\n",
      "    * Max Line Gap        :  22\n",
      "    * Grey Thresholding   :  11\n",
      "    * Hough Threshold     :  46\n",
      "    * Contour Threshold   :  500\n",
      "    \n",
      "    * Raw Contour Areas        : [2762.0, 1751.0, 4845.5, 2999.0, 7708.5, 1574.0, 398.0])\n",
      "    * Filtered Contour Areas   : [2762.0, 1751.0, 4845.5, 2999.0, 7708.5, 1574.0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Good Configuration:    for image = test/test_disparity.png)\n",
    "---------------------------------------------------------------\n",
    "    \n",
    "    * Mapping Space       : U-Map\n",
    "    * Line Finding Method : Probablistic Hough Transform\n",
    "    * Filtering Used      : Composite Filtering -> Blurring\n",
    "    * Kernel Size         : (2, 3)\n",
    "    * Rho, Angle (deg)    :  1, 90\n",
    "    * Min Line Length     :  11\n",
    "    * Max Line Gap        :  22\n",
    "    * Grey Thresholding   :  11\n",
    "    * Hough Threshold     :  46\n",
    "    * Contour Threshold   :  500\n",
    "    \n",
    "    * Raw Contour Areas        : [2762.0, 1751.0, 4845.5, 2999.0, 7708.5, 1574.0, 398.0])\n",
    "    * Filtered Contour Areas   : [2762.0, 1751.0, 4845.5, 2999.0, 7708.5, 1574.0])\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n"
     ]
    }
   ],
   "source": [
    "print(input_img.shape)\n",
    "plot_image(cv2.cvtColor(input_img,cv2.COLOR_GRAY2BGR))\n",
    "# bborder[np.where((bborder==[1,1,1]).all(axis=2))] = [255,0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   1.26229754, -340.1137798 ]), poly1d([   1.26229754, -340.1137798 ]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression,RANSACRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ransac_img = cv2.imread(\"/home/hunter/devel/vision_playground/input-lines.png\")\n",
    "nonzero_pxls = ransac_img.nonzero()\n",
    "nonzero_y = np.array(nonzero_pxls[0]).reshape(-1,1)\n",
    "nonzero_x = np.array(nonzero_pxls[1]).reshape(-1,1)\n",
    "\n",
    "# print(nonzero_x.shape, nonzero_y.shape)\n",
    "# quadratic = PolynomialFeatures(degree=2)\n",
    "# X_quad = quadratic.fit_transform(nonzero_x)\n",
    "# print(X_quad)\n",
    "# X_fit = np.arange(nonzero_x.min(), nonzero_x.max())[:, np.newaxis]\n",
    "\n",
    "# ransac = RANSACRegressor()\n",
    "# # model = make_pipeline(PolynomialFeatures(3), ransac)\n",
    "# # ransac.fit(nonzero_x, -nonzero_y)\n",
    "\n",
    "# model = make_pipeline(PolynomialFeatures(3), ransac)\n",
    "# model.fit(nonzero_x, -nonzero_y)\n",
    "# line_x = np.arange(nonzero_x.min(), nonzero_x.max())[:, np.newaxis]\n",
    "\n",
    "x_plot = np.linspace(nonzero_x.min(), nonzero_x.max())\n",
    "# y_plot = model.predict(x_plot[:, np.newaxis])\n",
    "# y_plot = model.predict(line_x)\n",
    "plt.close(5)\n",
    "plt.figure(5)\n",
    "# plt.scatter(nonzero_x, -nonzero_y, label='training points', color='lightgray')\n",
    "\n",
    "z = np.polyfit(nonzero_x[:,0], -nonzero_y[:,0], 1)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "print(z,p)\n",
    "plt.scatter(nonzero_x, -nonzero_y)\n",
    "plt.plot(x_plot, p(x_plot), \n",
    "         color='red', \n",
    "         lw=2,\n",
    "         linestyle='-')\n",
    " \n",
    "# plt.xlabel('% lower status of the population [LSTAT]')\n",
    "# plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "# plt.legend(loc='upper right')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (179,1) and (4,1) not aligned: 1 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-470-7dd3241d7309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mline_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonzero_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonzero_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mline_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mransac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/ransac.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 241\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (179,1) and (4,1) not aligned: 1 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# ransacL.fit(nonzerox_left, -nonzeroy_left)\n",
    "inlier_mask = ransac.inlier_mask_\n",
    "outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "# Predict data of estimated models\n",
    "line_x = np.arange(nonzero_x.min(), nonzero_x.max())[:, np.newaxis]\n",
    "print(line_x.shape)\n",
    "line_y = ransac.predict(line_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5)\n",
    "plt.scatter(nonzero_x, -nonzero_y, label='training points', color='lightgray')\n",
    "\n",
    "plt.plot(line_x, -line_y, \n",
    "         color='red', \n",
    "         lw=2,\n",
    "         linestyle='-')\n",
    " \n",
    "plt.xlabel('% lower status of the population [LSTAT]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.legend(loc='upper right')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustly fit linear model with RANSAC algorithm\n",
    "ransacL = linear_model.RANSACRegressor(residual_threshold=None, max_trials=50, stop_probability=0.90)\n",
    "ransacL.fit(nonzerox_left, -nonzeroy_left)\n",
    "inlier_maskL = ransacL.inlier_mask_\n",
    "outlier_maskL = np.logical_not(inlier_maskL)\n",
    "\n",
    "# Predict data of estimated models\n",
    "# line_xL = np.arange(nonzerox_left.min(), nonzerox_left.max())[:, np.newaxis]\n",
    "# line_yL = ransacL.predict(line_xL)\n",
    "\n",
    "# cv2.line(display_lines,(int(line_xL[0]),int(-line_yL[0] + y_offset)),(int(line_xL[-1]),int(-line_yL[-1] + y_offset)),(255,0,0),thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2, 2],\n",
      "       [4, 5]])\n",
      "(array([0, 0]), array([0, 1]))\n",
      "[[False False]\n",
      " [ True  True]]\n",
      "array([[0, 0],\n",
      "       [4, 5]])\n",
      "array([[2, 2],\n",
      "       [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import (\n",
    "    LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "nonzero_y = np.array(nonzero_pxls[0]).reshape(-1,1)\n",
    "nonzero_x = np.array(nonzero_pxls[1]).reshape(-1,1)\n",
    "ransac = RANSACRegressor()\n",
    "\n",
    "estimators = [('OLS', LinearRegression()),\n",
    "              ('Theil-Sen', TheilSenRegressor(random_state=42)),\n",
    "              ('RANSAC', RANSACRegressor(random_state=42)),\n",
    "              ('HuberRegressor', HuberRegressor())]\n",
    "colors = {'OLS': 'turquoise', 'Theil-Sen': 'gold', 'RANSAC': 'lightgreen', 'HuberRegressor': 'black'}\n",
    "linestyle = {'OLS': '-', 'Theil-Sen': '-.', 'RANSAC': '--', 'HuberRegressor': '--'}\n",
    "lw = 3\n",
    "\n",
    "x_plot = np.linspace(X.min(), X.max())\n",
    "for title, this_X, this_y in [\n",
    "        ('Modeling Errors Only', X, y),\n",
    "        ('Corrupt X, Small Deviants', X_errors, y),\n",
    "        ('Corrupt y, Small Deviants', X, y_errors),\n",
    "        ('Corrupt X, Large Deviants', X_errors_large, y),\n",
    "        ('Corrupt y, Large Deviants', X, y_errors_large)]:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(this_X[:, 0], this_y, 'b+')\n",
    "\n",
    "    for name, estimator in estimators:\n",
    "        model = make_pipeline(PolynomialFeatures(3), estimator)\n",
    "        model.fit(this_X, this_y)\n",
    "        mse = mean_squared_error(model.predict(X_test), y_test)\n",
    "        y_plot = model.predict(x_plot[:, np.newaxis])\n",
    "        plt.plot(x_plot, y_plot, color=colors[name], linestyle=linestyle[name],\n",
    "                 linewidth=lw, label='%s: error = %.3f' % (name, mse))\n",
    "\n",
    "    legend_title = 'Error of Mean\\nAbsolute Deviation\\nto Non-corrupt Data'\n",
    "    legend = plt.legend(loc='upper right', frameon=False, title=legend_title,\n",
    "                        prop=dict(size='x-small'))\n",
    "    plt.xlim(-4, 10.2)\n",
    "    plt.ylim(-2, 10.2)\n",
    "    plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
